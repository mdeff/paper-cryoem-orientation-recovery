\section{Method}

% \lau{Lau: As far as I'm concerned, everything below before subsection 2.1 could also go at the end of the Introduction. Beyond the fact that it contains literature review and conceptual information that would go well in the intro, I find the current architecture of Section 2 a bit puzzling. First there is text to explain the methods and detail their intuition/key components, then there are three consecutive subsections that kind of do the same, but from a maths points of view. The aforementioned suggestion of putting the first text in the intro could solve this. Another possibility: put the descriptive texts in their corresponding sub-sections, so that those contain both the motivation and the maths. I'm open to further suggestions and suggestions ;-) }
% \mdeff{Indeed. The "Distance Learning" and "Orientation Recovery" paragraphs might go in their respective sub-sections. But I'd like to keep a high-level motivation of the whole method (the text linked to the second figure to appear alongside \figref{imaging-geometry}.}
% \lau{Fine for me.}
% \banjac{I moved the DE and OR to corresponding subsections. The short intro to methods I left here at the beginning of the section 2 (I didn't move it to intro). Let me know if you meant something different}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{schematic_method_overview}
    \caption{%
        %\textbf{Method:}
        Our method consists of two steps.
        First, we estimate distances between pairs of projections.
        Second, we recover the orientation of each projection from these distances.
    }\label{fig:schematic:method-overview}
\end{figure}

Our approach relies on two observations (\figref{intuition-method}), yielding two steps (\figref{schematic:method-overview}).
First, the greater the similarity between two 2D projections $(\p_i, \p_j)$, the more likely they originated from two 3D particles that adopted close orientations $(q_i, q_j)$ in the ice layer prior to imaging;\footnote{Up to protein symmetries, which we discuss later.} this observation guides a number of applications in the field~\cite{frank2006three}.
% TODO: differences in orientation / distances
Hence, we aim to \textit{estimate distances} between orientations $d_q(q_i, q_j)$ from the projections themselves as $\widehat{d_p}(\p_i, \p_j)$, which we discuss in \secref{method:distance-learning}.
% where $\widehat{d_p}$ is learned from training data
% Sparse set of distances to a global assignment of orientations.
Second, an orientation $q$ is constrained by the distances between itself and the other orientations $\{ d(q, q_j) \}$.
Hence, we aim to \textit{recover orientations} $\{\widehat{q_k}\}$ such that the induced distances $\{ d_q(\widehat{q_i}, \widehat{q_j}) \}$ are close to the estimated distances $\{ \widehat{d_p}(\p_i, \p_j) \}$, which we discuss in \secref{method:orientation-recovery}.
%\todo{Second, we can learn the projection manifold by finding the distances that preserves the geometry of local neighborhoods in the space of orientations.}
All in all, from a set of projections $\{\p_k\}$, we aim to recover their orientations $\{\widehat{q_k}\}$ such that $d_q(\widehat{q_i}, \widehat{q_j}) \approx \widehat{d_p}(\p_i, \p_j) \approx d_q(q_i, q_j)$, with equality if $\widehat{d_p}$ and $\{\widehat{q_k}\}$ are perfectly estimated.
% Our method effectively (i) estimates a metric space, then (ii) embed/realize it in the space of 3D orientations, $\SO(3)$.

% Goal: we're not alone in doing that. Gives first intuitions on the method.
% line of work:
% 1. Graph Laplacian tomography from unknown random projections
% 2. Reference free structure determination through eigenvectors of center ofmass operators
% 3. Three-Dimensional Structure Determination from Common Lines in Cryo-EM by Eigenvectors and Semidefinite Programming
Our approach is similar to~\cite{coifman2008graphprojections}.
While the authors are there concerned with the reconstruction of 2D images from 1D projections, they rely on the same two-step approach: they (i) estimate distances as $\widehat{d_p}(\p_i, \p_j) = \| \p_i - \p_j \|_2$ then (ii) recover the orientations by spectrally embedding that distance graph.
% The authors built a graph with $\{\p_k\}$ as the vertex set and $\widehat{d_p}(\p_i, \p_j) = \| \p_i - \p_j \|_2$ as the edge distance, then recovered the orientations by spectrally embedding that graph.
The Euclidean distance is however not robust to perturbations:
for example, two projections that only differ by a shift $\mathbf{S_t}$ of one pixel would be considered far apart while their orientations are the same.
They noted that issue and we observed it too (\apxref{results:distance-estimation:euclidean}). To circumvent this, we propose to \textit{learn} $\widehat{d_p}$ from examples (\secref{method:distance-learning}).
% optimization vs eigenvectors (sensibility to outliers?)

%We propose to learn a function---parametrized as a neural network---to predict the relative orientation between two projections based on their similarity.
%This distance function then allows us to estimate, for any new projection dataset, the relative orientations between pairs of projections.

%\subsection{Unit Quaternions and the Geodesic Distance}
%\subsection{Parameterization of orientations}
\subsection{Representation of orientations with quaternions}\label{sec:method:orientation-representation}
%\subsection{Orientations and distances}\label{sec:method:orientation-representation}
%\subsection{Distance between orientations}
%\mdeff{Laur√®ne: Which word is better: Representation or parameterization? Or something else, but we need consistency.}
%\lau{Both are fine. Personally, I use parametrization in my thesis, but we can settle on the other one.}
% representation of orientations, parameterization of rotation matrices

%The projection $\mathbf{P}_{\bth}$ in \eqnref{imaging-model} represents an integration through the 3D particle made by the beam of electrons.
The orientation of a 3D particle with respect to the microscope's detector plane is a rotation relative to a reference orientation (\figref{imaging-geometry}).
The group of all 3D rotations under composition is identified with $\SO(3)$, the group of $3 \times 3$ orthogonal matrices with determinant~1 under matrix multiplication.
% non-commutative/non-Abelian\footnote{order of rotations matter}
A rotation matrix $\mathbf{R}_{\bth} \in \SO(3)$ can be decomposed as a product of $\binom{3}{2}=3$ independent rotations, for example as $\mathbf{R}_{\bth} = \mathbf{R}_{\theta_3} \mathbf{R}_{\theta_2} \mathbf{R}_{\theta_1}$, where $\bth = (\theta_3,\theta_2,\theta_1) \in [0,2\pi[ \, \times \, [0,\pi] \times [0,2\pi[$ are the (extrinsic and proper) Euler angles in the $ZYZ$ convention (a commonly-used parameterization in cryo-EM)~\cite{sorzano2014interchanging}.
%As illustrated in \figref{imaging-geometry}, $\mathbf{R}_{\theta_1}$ is a rotation about the $Z$-axis by the angle $\theta_1$, $\mathbf{R}_{\theta_2}$ is a rotation about the $Y$-axis by the azimuthal (or tilt) angle $\theta_2$, and $\mathbf{R}_{\theta_3}$ is a second rotation about the $Z$-axis by the in-plane angle $\theta_3$.
%The Euler angles $\bth$ and the rotation matrix $\mathbf{R}_\bth$ are equivalent representations of the orientation of a projection.

While Euler angles are a concise representation of orientation ($3$ numbers for $3$ degrees of freedom), they suffer from a topological constraint---there is no covering map from the $3$-torus to $\SO(3)$---which manifests itself in the \textit{gimbal lock}, the loss of one degree of freedom when $\theta_2=0$. %~\cite{koks2006explorations}
This makes their optimization by gradient descent (\secref{method:orientation-recovery}) problematic.
On the other hand, the optimization of rotation matrices (made of $9$ numbers) would require computationally costly constraints (orthogonality and determinant~1) to reduce the number of degrees of freedom to $3$.
Moreover, the distance between orientations cannot be directly computed from Euler angles and is costly (30 multiplications) to compute from rotation matrices~\cite{huynh2009metrics}.
We solve both problems by representing orientations with unit quaternions.

%\paragraph{Quaternions.}
Quaternions $q \in \mathbb{H}$ are an extension of complex numbers\footnote{The algebra $\mathbb{H}$ is similar to the algebra of complex numbers $\mathbb{C}$, with the exception of multiplication being non-commutative.} of the form $q = a + b\boldsymbol{i} + c\boldsymbol{j} + d\boldsymbol{k}$ where $a,b,c,d \in \R$.
Unit quaternions $q \in \mathbb{S}^3$, where $\mathbb{S}^3 = \big\{ q \in \mathbb{H}: \lvert q \rvert = 1 \big\}$ is the 3-sphere (with the additional group structure inherited from quaternion multiplication), concisely and elegantly represent a rotation of angle $\theta$ about axis $(x_1, x_2, x_3)$ as $q = \cos(\theta/2) + x_1 \sin(\theta/2) \boldsymbol{i} + x_2 \sin(\theta/2) \boldsymbol{j} + x_3 \sin(\theta/2) \boldsymbol{k}$.
They parameterize rotation matrices as
\begin{equation*}
    \mathbf{R}_q =
    \begin{pmatrix}
        a^2+b^2-c^2-d^2 & 2bc-2ad & 2bd+2ac \\
        2bc+2ad & a^2-b^2+c^2-d^2 & 2cd-2ab \\
        2bd-2ac & 2cd+2ab & a^2-b^2-c^2+d^2
    \end{pmatrix}.
\end{equation*}
%Composition of rotations is given by multiplications of quaternions.
Note that $\mathbb{S}^3 \rightarrow \SO(3)$ is a two-to-one mapping (a double cover) as $q$ and $-q$ represent the same orientation.
%, \ie, antipodal points of $\mathbb{S}^3$ are equivalent.
% q=-q is like rotation by the negated angle in the opposed direction
%\paragraph{Distances.}
Unlike Euler angles, $\mathbb{S}^3$ is isomorphic to the universal cover of $\SO(3)$.
Hence, the distance between two orientations, \ie, the length of the geodesic between them on $\SO(3)$, is given by
\begin{equation}
    \begin{aligned}
        d_q &: \mathbb{S}^3 \times \mathbb{S}^3 \rightarrow [0,\pi], \\
        d_q(q_i, q_j) &= 2 \arccos \left( \left| \langle q_i, q_j \rangle \right| \right),
    \label{eqn:distance:orientations}
    \end{aligned}
\end{equation}
where $\langle \cdot, \cdot \rangle$ is the inner product, and the absolute value $\left| \cdot \right|$ ensures that $d_q(q_i, q_j) = d_q(q_i, -q_j)$.
The distance $d_q(q_i, q_j)$ corresponds to the magnitude (angle $\theta$) of the rotation $\mathbf{R}_*$ such that $\mathbf{R}_{q_i} = \mathbf{R}_* \mathbf{R}_{q_j}$~\cite{huynh2009metrics}.

%For the sake of conciseness, we shall use the term ``with orientation~$q$'' to refer to 2D/3D objects considered in an imaging geometry parametrized by $q$.

% Euler angles:
% - Euler angles are not unique
% - gimbal lock problem
% - intuition behind changing the basis between two coordinate systems is not so clear
% - to compare if 2 different projs are close to each other in their projection directions, it does not suffice comparing their 2 sets of Euler angle sets
% - 3 unknown parameters
% - just used for representation of input and output format of rotation

% Affine transformations / rotation matrices:
% - intuitive
% - unique
% - 3x3 matrix, 9 parameters
% - used for angle alignment due to its transformation versatility (\eg mirrors)
% simpler to compose
% avoid problem of gimbal lock
%Rotation matrix: Minor disadvantage: Multiplication of matrices is ~2 times slower than quaternions. Minor Advantage: Matrix-vector multiplication is ~2 times faster, and large. Huge disadvantage: Normalization! Ghram-Shmit is asymmetrical, which does not give a higher order accurate answer when doing differential equations. More sophisticated methods are very complex and expensive.

% Quaternions:
% - intuition behind changing the basis between two coordinate systems is not so clear
% - 4D vector, 4 unknown parameters
% - much less known in EM community, but they can be used to describe rotation
% - any time we need to perform rotation on camera position, the quaternion is translated into its corresponding rotation matrix and then it is applied to the coordinates of the central coordinate system
% - mirroring using quaternions - we lose any intuition about how two projection directions (mirrored and non-mirrored) are related
% more compact and numerically stable
%Unfortunately, the intuition behind changing the basis between two coordinate systems is not so clear and performing reflections (also known as mirrors, flips) using quaternions we lose any intuition about how two projection directions (mirrored and non-mirrored) are related.
%However, quaternions are more compact (4D vectors/4 scalars) and numerically stable compared to rotation matrices.
%The quaternions strike a nice balance of both, Euler angles and rotation matrices, being small and free from gimbal lock.

% Axis angles
% - used for visualizations
%Axis (angle = length of axis) Minor advantage: Small. Moderate disadvantage: Multiplication and applying to a vector is slow with trig. Moderate disadvantage: North-pole singularity at length = 2*pi, since all axis directions do nothing. More code (and debugging) to automatically rescale it when it gets near 2pi.

\subsection{Distance learning}\label{sec:method:distance-learning}
%\subsection{Metric learning}%\label{sec:method:distance-learning}
%\subsection{Estimating Relative Orientations from Projections}
%\subsection{Relative orientation estimation}
%\subsection{Relative orientation estimation from projections}

%We aim to learn a function $\widehat{d_p}$---parametrized as a neural network---to predict the relative orientation between two projections based on their similarity.

We aim to estimate a function $\widehat{d_p}$ such that $\widehat{d_p}(\p_i, \p_j) \approx d_q(q_i, q_j)$.
While we could in principle design $\widehat{d_p}$, that would be intricate---if not impossible---partly because the invariants are difficult to specify.
We instead opt to learn $\widehat{d_p}$, capitalizing on (i) the powerful function approximation capabilities of neural networks, and (ii) the possibility to generate realistic cryo-EM projection datasets supported by the availability of numerous 3D atomic models\footnote{\url{https://www.ebi.ac.uk/pdbe/emdb}} and our ability to model the imaging procedure.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{schematic_distance_learning}
    \caption{%
        Distance learning.
        We are looking for a distance $\widehat{d_p}$ between projections that is an accurate estimator of the distance $d_q$ between their orientations.
        We propose to parameterize $\widehat{d_p}$ as a Siamese neural network (SiameseNN), trained on a synthetic dataset of projections with associated orientation.
        %\mdeff{Why the output "loss" arrow? To me, this system is closed.}
        %\mdeff{"Loss Function" could be called Optimization or Learning or Training.}
}\label{fig:schematic:distance-learning}
\end{figure}

From a training dataset ${\{ \p_i, q_i \}}_{i=1}^{P}$, we learn the projection distance
\begin{equation}
    \widehat{d_p} = \argmin_{d_p} L_\text{DE},
    \quad \text{where} \quad
    L_\text{DE} = \sum_{i,j} \left| d_p\big(\p_i,\p_j\big) - d_q\big(q_i,q_j\big) \right|^2
    \label{eqn:distance-learning}
\end{equation}
is the loss and $d_q$ is defined in~\eqnref{distance:orientations}.
The distance $d_p$ is parameterized as the Siamese neural network (SiameseNN)~\cite{chopra2005learning}
\begin{equation*}
    d_p(\p_i, \p_j) = d_f(\G_w(\p_i), \G_w(\p_j)),
    %\label{eqn:distance:projections}
\end{equation*}
where $\G_w$ is a convolutional neural network with weights $w$ that is trained to extract the most relevant features $\f_i \in \R^{n_f}$ from a projection $\p_i$.
SiameseNNs, also termed ``twin networks'', are commonly used in the field of deep metric learning to learn similarity functions~\cite{yi2014deep}.
We set the feature space distance $d_f$ as the cosine distance to facilitate the learning of a $\widehat{d_p}$ that respects the elliptic geometry of $\mathbb{S}^3$ (\apxref{siamese:feature-distance-and-embedding-dimension}).
\figref{schematic:distance-learning} illustrates the proposed learning paradigm.

% $\frac{P^2-P}{2}$ is lower but we use P^2 in practice. Also, NN needs to learn d(p,p)=0 and is not necessarily symmetric depending on d_f.
As evaluating a sum over $P^2$ pairs is computationally intractable for cryo-EM datasets with typically $P$ in the order of $10^5$ projections, we sample the sum and minimize \eqnref{distance-learning} with stochastic gradient descent (SGD) over small batches of pairs.
The weights $w$ are updated by back-propagation.
% error / objective value

The architecture of $\G_w$ is described in \apxref{siamese-architecture}.
% with $n_f=512$.
% \mdeff{Architecture of $G_w$ doesn't seem to matter much. Surprising, because we don't overfit $\rightarrow$ future research needed.}
%\todo{Jelena: could we say some words on how you selected the NN architecture? And hyperparameters selection and tuning of the neural network layers,}
When designing the architecture, we constrain the functional space from which the trained $\G_w$ is drawn and express our prior expert knowledge.
% which then gives us a generalization guarantee.
For example, we realize shift invariance, \ie, a guarantee that a shift $\mathbf{S_t}$ does not change our estimated distances and orientations, with a fully convolutional architecture.
Size invariance, \ie, taking projections $\p$ of varying sizes $n_p$ while yielding a representation $\f$ of a fixed size $n_f$, is realized by a final average pooling layer.
As we do not (yet) know how to realize an invariance to noise or PSF, we resort to data augmentation, \ie, training on perturbed projections.
In \secref{results:distance-estimation:sensitivity}, we show that a built-in invariance (shift) is far preferable to one learned through augmentation (noise).
Finally, as projections are made by integrating through the 3D volume, projections from opposed directions $(\theta_2,\theta_1)$ are mirrors of each other.%
\footnote{That fact prevents cryo-EM reconstruction to resolve chirality, \ie, it cannot distinguish a protein from its mirrored version.}
%cannot tell whether the protein was mirrored.
% chirality/handedness
%A protein is chiral if it cannot be superposed on its mirror image by any combination of shifts or rotations.
% \lau{I searched for a ref, but I don't think there is a relevant one. In a recent paper from Amit Singer (a big name in cryo-EM), they simply mention "The reconstruction of œÜ is possible up to three intrinsic ambiguities: a global 3-D rotation, the position of the center of the molecule (3-D location), and handedness. The latter symmetry, also called chirality, means that it is impossible to distinguish whether the molecule was reflected about a 2-D plane through the origin". Thus I suggest we don't include a ref.}
That is another kind of physical knowledge that should ideally be built into our method.
%\mdeff{Not only a rotation, but an integration through $z_3$. (As opposed projections are mirrored, we cannot resolve chirality. Projecting looses global orientation, integrating looses chirality.)}
% "fundamental issue with reconstruction in cryoEM in general."
% at high resolutions, the handedness can be determined by the chirality of alpha helices
% https://discuss.cryosparc.com/t/ab-initio-reconstruction-chirality-issue/2202

One could hope to train $\mathcal{G}_w$ to directly map projections to orientations as $\widehat{q_i} = \f_i = \G_w(\p_i)$.
While that would avoid the orientation recovery step, a space of $n_f=4$ dimensions does not have room for $\mathcal{G}_w$ to represent the other factors of variation in $\p$, such as different noise levels, PSFs, or proteins.
% While those factors can be represented, they are then abstracted by taking distances.
We tested that hypothesis in \apxref{siamese:feature-distance-and-embedding-dimension}.

\subsection{Orientation recovery}\label{sec:method:orientation-recovery}
%\subsection{Orientation recovery from relative orientations}

The task of recovering points based on their relative distances has been extensively studied.
%For dimensionality reduction and data visualization, the distances are often computed from high-dimensional data.
Many methods aim at mapping high-dimensional data onto a lower-dimensional space while preserving distances, primarily for dimensionality reduction and data visualization.
%A set of distances is often built as an intermediate step.
%More specifically, these algorithms take a matrix of distances and find vectors in a lower dimensional space that accurately match the inter-vector distances.
Well-known examples include multi-dimensional scaling (MDS)~\cite{cox2008mds}, Isomap~\cite{tenenbaum2000isomap}, locally linear embedding (LLE)~\cite{roweis2000lle}, Laplacian eigenmaps~\cite{belkin2003laplacian}, t-distributed stochastic neighbor embedding (t-SNE)~\cite{maaten2008tsne}, and uniform manifold approximation and projection (UMAP)~\cite{mcinnes2018umap}.
The embedding of distance matrices in Euclidean space (given by their eigenvectors) is especially well-described.
In particular, the framework of Euclidean distance matrices (EDMs)~\cite{dokmanic2015edm} provides theoretical guarantees on the recovery of points from distances.

We however aim to embed the orientations $q$ in $\mathbb{S}^3$ (\secref{method:orientation-representation}), a setting for which we are unaware of any theoretical characterization (\eg, on the shape of the loss function or its behavior when distances are missing or noisy).
The fact that $\mathbb{S}^3$ is locally Euclidean does however offer some hope. % on the feasibility of this minimization.
Indeed, despite the non-convexity and the lack of theoretical guarantees, we are able to appropriately minimize our loss function, as we experimentally demonstrate in \apxref{results:orientation-recovery:exact}.

We recover the orientations of a set of projections $\big\{ \mathbf{p}_k \big\}_{k=1}^P$ through
\begin{equation}
    \big\{ \widehat{q_k} \big\}_{k=1}^P = \argmin_{\{q_k \in \mathbb{S}^3\}} L_\text{OR},
    \quad \text{where} \quad
    L_\text{OR} = \sum_{i,j} \left| \widehat{d_p} \left( \p_i, \p_j \right) - d_q\left(q_i,q_j\right) \right|^2
    \label{eqn:orientation-recovery}
\end{equation}
is the loss and $\widehat{d_p}$ is the estimator trained in \eqnref{distance-learning}.
Note that the sole difference with~\eqnref{distance-learning} is that the minimization is performed over the orientations $q$ rather than the distance $d_p$.
Here again, we sample the sum in practice and minimize \eqnref{orientation-recovery} with mini-batch SGD.
Sampling the sum amounts to building a sparse (instead of complete) distance graph before embedding, a common strategy.
%We experimentally demonstrate in \secref{results:orientation-recovery:exact} that neither approximation affects recovery performance.
%\todo{Orientations were recovered through \eqnref{orientation-recovery} in a stochastic setting, with the loss function varying over the batches.}

\subsection{Evaluation}\label{sec:method:evaluation}

%\todo{Introduce the mean recovery error as a good and intuitive performance metric.}
%\todo{Figure that shows a typical convergence and mean orientation recovery error before and after alignment. We'll subsequently only report $E$ (the error after alignment).}

While not a part of the method \textit{per se}, the evaluation of the orientations recovered by~\eqnref{orientation-recovery} is essential for assessing the quality of the obtained results.
% (without reconstructing the protein)
%Before discussing the results, we remark that one cannot directly quantify the performance of~\eqnref{orientation-recovery} through its loss nor visual judgment of the protein reconstruction.
Unfortunately, we cannot directly take the difference between the recovered orientations $\{\widehat{q_k}\}_{k=1}^P$ and the true orientations $\{q_k\}_{k=1}^P$ as orientations are rotations up to an arbitrary reference orientation.
Any global rotation or reflection of the recovered orientations is as valid as any other, \ie, $d_q(q_i, q_j) = d_q(\T q_i , \T q_j) \; \forall \, \T \in \Or(4)$, where $\Or(4)$ is the group of $4 \times 4$ orthogonal matrices. % that represent the symmetries of $\mathbb{S}^3$ (isometries of $\R^4$) of 4D Euclidean space.
Hence, we align the sets of orientations and compute the \textit{mean orientation recovery error} as
\begin{equation}
    E_\text{OR} = \min_{\T \in \Or(4)} \frac{1}{P} \sum_{i=1}^P \big| d_q\left( q_i, \T \widehat{q_i} \right) \big|.
    \label{eqn:orientation-recovery-error}
\end{equation}
We implement $\T$ as a product of $\binom{4}{2}=6$ independent rotations and an optional reflection defined as 
$
    \T =
    \begin{bmatrix}
        m & \mathbf{0} \\
        \mathbf{0} & \mathbf{I} \\
    \end{bmatrix}
    \prod_{1 \leq i < j \leq 4} \mathbf{T}_{\theta_{ij}},
    \quad m \in \{-1,1\}, \; \theta_{ij} \in [0, 2\pi[,
$
where $m = \det(\T) = -1$ if $\T$ includes a reflection, and $\mathbf{T}_{\theta_{ij}} \in \SO(4)$ is a rotation by angle $\theta_{ij}$ on the $(x_i, x_j)$ plane.

In practice, we again minimize \eqnref{orientation-recovery-error} with mini-batch SGD.
Because $\Or(4)$ is disconnected, we optimize the 6 angles separately for $m = 1$ (proper rotations) and $m = -1$ (improper rotations).
\figref{5j0n-aa-loss-perfect-distances} shows an alignment to $E_{OR}=0$ after a perfect recovery.

%Alternative metrics are discussed in \apxref{metrics-review}.
%\todo{While it requires optimization, this performance metric is intuitive as it gives average error of the estimated orientations.}
%\mdeff{Why is it good? Intuitive. Laur√®ne, can we say something more?} \lau{If really, something along the line "... allows to quantify the performance of orientation recovery with a measure that is more intuitive to grasp."}
%\banjac{While it requires optimization, this performance metric allows to quantify the performance of orientation recovery with a measure that is more intuitive to grasp.}
